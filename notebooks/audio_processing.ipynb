{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from os.path import isfile, join, normpath\n",
    "# import wget\n",
    "import scipy.io\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Audio Data From Online Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dateset_URL = ''\n",
    "HOME = 'C:\\Users\\claud\\OneDrive\\Documents\\School\\T7\\50.039 DL\\Deep_Learning_Denoiser\\noisy_samples\\noise_sample_177659.wav'\n",
    "\n",
    "dataset = wget.download(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 107136]) 48000\n",
      "tensor(0.2032)\n"
     ]
    }
   ],
   "source": [
    "path = '..\\\\data\\\\clean_audio_WAV\\\\common_voice_en_1.wav'\n",
    "waveform, sample_rate = torchaudio.load(path)\n",
    "print(waveform.shape,sample_rate)\n",
    "\n",
    "resampler = torchaudio.transforms.Resample(48000, 22050)\n",
    "resampled_waveform = resampler(waveform)\n",
    "print(max(resampled_waveform[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = torch.split(waveform, 200_000, dim=1)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 49216]) 22050\n",
      "torch.Size([1, 107137])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "path = '..\\\\data\\\\noisy_audio_WAV\\\\noisy_0.wav'\n",
    "waveform, sample_rate = torchaudio.load(path)\n",
    "print(waveform.shape,sample_rate)\n",
    "\n",
    "resampler = torchaudio.transforms.Resample(22050, 48000)\n",
    "resampled_waveform = resampler(waveform)\n",
    "print(resampled_waveform.shape)\n",
    "print(resampled_waveform.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 107136])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = '.\\\\noisy_samples\\\\common_voice_en_1.mp3'\n",
    "path = '..\\\\data\\\\clean_audio_tensors\\\\common_voice_en_1.pt'\n",
    "# path = '.\\\\noisy_samples\\\\noise_sample_62094.wav'\n",
    "waveform = torch.load(path)\n",
    "waveform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 49216])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '..\\\\data\\\\noisy_audio_tensors\\\\noisy_0.pt'\n",
    "waveform = torch.load(path)\n",
    "waveform.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Silent Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:04<00:00, 2400.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('./data/clean_audio_tensors/common_voice_en_100543.pt',\n",
      "  './data/noisy_audio_tensors/noisy_613.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_100544.pt',\n",
      "  './data/noisy_audio_tensors/noisy_614.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_100545.pt',\n",
      "  './data/noisy_audio_tensors/noisy_615.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_101610.pt',\n",
      "  './data/noisy_audio_tensors/noisy_1945.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_101611.pt',\n",
      "  './data/noisy_audio_tensors/noisy_1946.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_101612.pt',\n",
      "  './data/noisy_audio_tensors/noisy_1947.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10327.pt',\n",
      "  './data/noisy_audio_tensors/noisy_4433.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10328.pt',\n",
      "  './data/noisy_audio_tensors/noisy_4444.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10329.pt',\n",
      "  './data/noisy_audio_tensors/noisy_4455.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10330.pt',\n",
      "  './data/noisy_audio_tensors/noisy_4467.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10331.pt',\n",
      "  './data/noisy_audio_tensors/noisy_4484.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10332.pt',\n",
      "  './data/noisy_audio_tensors/noisy_4495.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_103505.pt',\n",
      "  './data/noisy_audio_tensors/noisy_4701.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_103506.pt',\n",
      "  './data/noisy_audio_tensors/noisy_4702.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_103507.pt',\n",
      "  './data/noisy_audio_tensors/noisy_4703.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10377.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5015.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10378.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5026.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10379.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5037.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10380.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5049.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10381.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5060.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10382.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5071.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10383.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5085.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10384.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5096.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10385.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5107.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10386.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5118.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10387.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5129.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10388.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5189.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10389.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5200.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10390.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5212.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10391.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5223.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10395.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5267.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10396.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5278.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10397.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5289.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10398.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5300.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10399.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5311.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_10400.pt',\n",
      "  './data/noisy_audio_tensors/noisy_5339.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_106165.pt',\n",
      "  './data/noisy_audio_tensors/noisy_7999.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_106184.pt',\n",
      "  './data/noisy_audio_tensors/noisy_8026.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_106215.pt',\n",
      "  './data/noisy_audio_tensors/noisy_8061.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_106354.pt',\n",
      "  './data/noisy_audio_tensors/noisy_8215.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_106356.pt',\n",
      "  './data/noisy_audio_tensors/noisy_8216.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_107243.pt',\n",
      "  './data/noisy_audio_tensors/noisy_9354.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_107244.pt',\n",
      "  './data/noisy_audio_tensors/noisy_9355.pt'),\n",
      " ('./data/clean_audio_tensors/common_voice_en_107245.pt',\n",
      "  './data/noisy_audio_tensors/noisy_9356.pt')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_input = '../data/clean_audio_tensors'\n",
    "path_output = '../data/noisy_audio_tensors'\n",
    "\n",
    "silent_audio = []\n",
    "\n",
    "file_data = [f for f in listdir(path_input) if isfile (join(path_input, f))]\n",
    "for idx, line in enumerate(tqdm(file_data)):\n",
    "    if ( line[-1:] == '\\n' ):\n",
    "        line = line[:-1]\n",
    "\n",
    "    # Reading Song\n",
    "    songname = path_input + '/' + line\n",
    "    # save_dest = path_output + '/' + line.split('.')[0] + '.pt'\n",
    "    # save_dest = path_output + '/' + line.split('.')[0] + '.pt'\n",
    "    # print(save_dest)\n",
    "    output_audio = path_output + '/noisy_' + str(idx) + '.pt'\n",
    "\n",
    "    waveform = torch.load(songname)[0]\n",
    "\n",
    "    if waveform.sum().item() == 0:\n",
    "        silent_audio.append((songname, output_audio))\n",
    "\n",
    "\n",
    "pprint(silent_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/clean_audio_tensors\\./data/noisy_audio_tensors\n"
     ]
    }
   ],
   "source": [
    "print(join(path_input,path_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "print(len(silent_audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "silent_path = '../data/silent_audio'\n",
    "\n",
    "for files in silent_audio:\n",
    "    clean, noisy = files[0], files[1]\n",
    "    \n",
    "    clean_filename = clean.split('/')[-1]\n",
    "    noisy_filename = noisy.split('/')[-1]\n",
    "\n",
    "    shutil.move(clean, join(silent_path,clean_filename))\n",
    "    shutil.move(noisy, join(silent_path,noisy_filename))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9956/9956 [02:32<00:00, 65.30it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "path_input = '../data/clean_audio_tensors'\n",
    "path_output = '../data/clean_audio_tensors_v2'\n",
    "\n",
    "silent_audio = []\n",
    "\n",
    "def pad(data, size):\n",
    "    assert data.size(dim=1) <= size\n",
    "    if data.size(dim=1) == size:\n",
    "        return data\n",
    "    padded_data  = F.pad(data, pad=(0, size - data.shape[1]))\n",
    "    return padded_data  \n",
    "\n",
    "\n",
    "\n",
    "file_data = [f for f in listdir(path_input) if isfile (join(path_input, f))]\n",
    "for idx, line in enumerate(tqdm(file_data)):\n",
    "    if ( line[-1:] == '\\n' ):\n",
    "        line = line[:-1]\n",
    "\n",
    "    # Reading Song\n",
    "    songname = path_input + '/' + line\n",
    "    # save_dest = path_output + '/' + line.split('.')[0] + '.pt'\n",
    "    # save_dest = path_output + '/' + line.split('.')[0] + '.pt'\n",
    "    # print(save_dest)\n",
    "    # output_audio = path_output + '/noisy_' + str(idx) + '.pt'\n",
    "\n",
    "    waveform = torch.load(songname)\n",
    "\n",
    "    splits = list(torch.split(waveform, 22_050, dim=1))\n",
    "    splits[-1] = pad(splits[-1], 22050)\n",
    "    \n",
    "\n",
    "    for s_idx, split in enumerate(splits):\n",
    "        fn = 'clean' + str(idx) + '_' + str(s_idx) + '.pt'\n",
    "        torch.save(split, os.path.join(path_output, fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_input = '../data/Hl2_Rebel-Ragdoll485-573931361.wav'\n",
    "\n",
    "waveform, samplerate = torchaudio.load(path_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 123942])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 123942])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.mean(waveform, dim=0).unsqueeze(0)\n",
    "\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output = '../data/torture.wav'\n",
    "torchaudio.save(path_output, a, 44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Sanity Check Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n"
     ]
    }
   ],
   "source": [
    "input_path = '..\\\\data\\\\clean_sanity_check\\\\p234_002.wav'\n",
    "\n",
    "waveform, sr = torchaudio.load(input_path)\n",
    "\n",
    "print(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0010)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform[0][0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

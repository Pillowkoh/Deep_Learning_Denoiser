{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3060 Ti'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.device(0)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISY_SAMPLES = os.path.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Denoiser(torch.nn.Module):\n",
    "  # D: no of encoder layers\n",
    "  # H: no. of output channels in first layer\n",
    "  # K: kernel size\n",
    "  # S: stride\n",
    "  def __init__(\n",
    "  self, \n",
    "  n_layers, \n",
    "  output_channels, \n",
    "  chin=1,\n",
    "  chout=1,\n",
    "  hidden=48,\n",
    "  depth=5,\n",
    "  N_attention = 3,\n",
    "  kernel_size=8,\n",
    "  stride=4,\n",
    "  causal=True,\n",
    "  resample=4,\n",
    "  growth=2,\n",
    "  max_hidden=10_000,\n",
    "  normalize=True,\n",
    "  glu=True,\n",
    "  rescale=0.1,\n",
    "  floor=1e-3,\n",
    "  sample_rate=22_050\n",
    "  ):\n",
    "    super(Denoiser, self).__init__()\n",
    "    self.D = n_layers\n",
    "    self.H = output_channels\n",
    "    self.K = kernel_size\n",
    "    self.S = kernel_size // 2\n",
    "\n",
    "    self.encoder = nn.ModuleList([])\n",
    "    self.decoder = nn.ModuleList([])\n",
    "    self.attention = nn.ModuleList([])\n",
    "    activation = nn.GLU(1) if glu else nn.ReLU()\n",
    "    ch_scale = 2 if glu else 1\n",
    "\n",
    "    for index in range(depth):\n",
    "\n",
    "      encode = []\n",
    "      encode += [\n",
    "          nn.Conv1d(chin, hidden, kernel_size, stride),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv1d(hidden, hidden * ch_scale, 1),\n",
    "          activation,\n",
    "      ]\n",
    "      self.encoder.append(nn.Sequential(*encode))\n",
    "\n",
    "      decode = []\n",
    "      decode += [\n",
    "          nn.Conv1d(hidden, ch_scale * hidden, 1),\n",
    "          activation,\n",
    "          nn.ConvTranspose1d(hidden, chout, kernel_size, stride),\n",
    "      ]\n",
    "      if index > 0:\n",
    "          decode.append(nn.ReLU())\n",
    "      self.decoder.insert(0, nn.Sequential(*decode))\n",
    "      chout = hidden\n",
    "      chin = hidden\n",
    "      hidden = min(int(growth * hidden), max_hidden)\n",
    "\n",
    "    for i in range(N):\n",
    "      attention = []\n",
    "      attention += [\n",
    "        nn.MultiheadAttention(embed_dim=chin, num_heads=8),\n",
    "        nn.Linear(chin, 2*chin),\n",
    "        nn.Linear(2*chin, chin)\n",
    "      ]\n",
    "      self.attention.append(nn.Sequential(*attention))\n",
    "\n",
    "  def forward(self, input):\n",
    "    length = input.shape[-1]\n",
    "    skip_outputs = []\n",
    "    for encoder in self.encoder:\n",
    "      x = encoder(x)\n",
    "      skip_outputs.append(x)\n",
    "\n",
    "    # x = x.permute(2, 0, 1)\n",
    "    # x, _ = self.attention(x)\n",
    "    # x = x.permute(1, 2, 0)\n",
    "    for attention in self.attention:\n",
    "      x, _ = attention(x, x, x)\n",
    "    \n",
    "    for decode in self.decoder:\n",
    "        skip = skip_outputs.pop(-1)\n",
    "        x = x + skip[..., :x.shape[-1]]\n",
    "        x = decode(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, loss_fn, optimizer, epochs, scheduler = None):\n",
    "        self.model = model\n",
    "        self.loss = {\"train\":[], \"val\":[]}\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.epochs = epochs\n",
    "        self.scheduler = scheduler\n",
    "        self.checkpoint_frequency = 100\n",
    "        self.early_stopping_epochs = 10\n",
    "        self.early_stopping_avg = 10\n",
    "        self.early_stopping_precision = 5\n",
    "\n",
    "    def train(self, train_dataloader, val_dataloader):\n",
    "        for epoch in range(self.epochs):\n",
    "            self._epoch_train(train_dataloader)\n",
    "            self._epoch_eval(val_dataloader)\n",
    "            print(\n",
    "                \"Epoch: {}/{}, Train Loss={}, Val Loss={}\".format(\n",
    "                    epoch + 1,\n",
    "                    self.epochs,\n",
    "                    np.round(self.loss[\"train\"][-1], 10),\n",
    "                    np.round(self.loss[\"val\"][-1], 10),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # reducing LR if no improvement\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step(self.loss[\"train\"][-1])\n",
    "\n",
    "            # saving model\n",
    "            if (epoch + 1) % self.checkpoint_frequency == 0:\n",
    "                torch.save(\n",
    "                    self.model.state_dict(), \"model_{}\".format(str(epoch + 1).zfill(3))\n",
    "                )\n",
    "\n",
    "            # early stopping\n",
    "            if epoch < self.early_stopping_avg:\n",
    "                min_val_loss = np.round(np.mean(self.loss[\"val\"]), self.early_stopping_precision)\n",
    "                no_decrease_epochs = 0\n",
    "\n",
    "            else:\n",
    "                val_loss = np.round(\n",
    "                    np.mean(self.loss[\"val\"][-self.early_stopping_avg:]), \n",
    "                                    self.early_stopping_precision\n",
    "                )\n",
    "                if val_loss >= min_val_loss:\n",
    "                    no_decrease_epochs += 1\n",
    "                else:\n",
    "                    min_val_loss = val_loss\n",
    "                    no_decrease_epochs = 0\n",
    "                    #print('New min: ', min_val_loss)\n",
    "\n",
    "            if no_decrease_epochs > self.early_stopping_epochs:\n",
    "                print(\"Early Stopping\")\n",
    "                break\n",
    "\n",
    "        torch.save(self.model.state_dict(), \"model_final\")\n",
    "        return self.model\n",
    "\n",
    "\n",
    "    def _epoch_train(self, dataloader):\n",
    "        self.model.train()\n",
    "        running_loss = []\n",
    "\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            inputs = data[\"noisy\"].to(self.device)\n",
    "            labels = data[\"clean\"].to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            running_loss = []\n",
    "\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss.append(loss.item())\n",
    "\n",
    "            if i == self.batches_per_epoch:\n",
    "                epoch_loss = np.mean(running_loss)\n",
    "                self.loss[\"train\"].append(epoch_loss)\n",
    "                break\n",
    "\n",
    "    def _epoch_eval(self, dataloader):\n",
    "        self.model.eval()\n",
    "        running_loss = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(dataloader, 0):\n",
    "                inputs = data[\"noisy\"].to(self.device)\n",
    "                labels = data[\"clean\"].to(self.device)\n",
    "\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.loss_fn(outputs, labels)\n",
    "\n",
    "                running_loss.append(loss.item())\n",
    "\n",
    "                if i == self.batches_per_epoch_val:\n",
    "                    epoch_loss = np.mean(running_loss)\n",
    "                    self.loss[\"val\"].append(epoch_loss)\n",
    "                    break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
